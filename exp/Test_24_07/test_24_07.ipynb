{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Creating environment from the given name 'BreakoutNoFrameskip-v4'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Using custom NatureCNN feature extractor with added variance estimation\n",
      "Created a buffer for images of shape torch.Size([1000, 100800]) and latents torch.Size([1000, 128])\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 623      |\n",
      "|    ep_rew_mean     | 0.667    |\n",
      "| time/              |          |\n",
      "|    fps             | 193      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 701         |\n",
      "|    ep_rew_mean          | 1.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 199         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008456919 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -14.3       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 557         |\n",
      "|    ep_rew_mean          | 0.333       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017297272 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -2.32       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.989       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    value_loss           | 0.0609      |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 671         |\n",
      "|    ep_rew_mean          | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 195         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008567277 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -1.53       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    value_loss           | 0.0333      |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 653        |\n",
      "|    ep_rew_mean          | 1.33       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 169        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01609814 |\n",
      "|    clip_fraction        | 0.0853     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | -0.574     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.997      |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.00541   |\n",
      "|    value_loss           | 0.0255     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 566          |\n",
      "|    ep_rew_mean          | 0.5          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 160          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047795805 |\n",
      "|    clip_fraction        | 0.0493       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.988        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 0.0175       |\n",
      "------------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 970         |\n",
      "|    ep_rew_mean          | 3           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 170         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003454505 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.977       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    value_loss           | 0.0187      |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 548         |\n",
      "|    ep_rew_mean          | 0.333       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 194         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009136865 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.986       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.028       |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 629         |\n",
      "|    ep_rew_mean          | 0.667       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 194         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002510163 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.00975    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.982       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.00913     |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 650         |\n",
      "|    ep_rew_mean          | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 199         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005324074 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.973       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 631         |\n",
      "|    ep_rew_mean          | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 188         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012139659 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.949       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.0116      |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 581         |\n",
      "|    ep_rew_mean          | 0.667       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 187         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021056399 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.965       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.012       |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 654         |\n",
      "|    ep_rew_mean          | 1.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016125046 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.957       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.0108      |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 580         |\n",
      "|    ep_rew_mean          | 0.667       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 178         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033787146 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.973       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.0164      |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 555         |\n",
      "|    ep_rew_mean          | 0.333       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 187         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038794093 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.976       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 0.011       |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 563        |\n",
      "|    ep_rew_mean          | 0.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 181        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04061847 |\n",
      "|    clip_fraction        | 0.4        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 0.0919     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.971      |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0323    |\n",
      "|    value_loss           | 0.00929    |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 708         |\n",
      "|    ep_rew_mean          | 1.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046619833 |\n",
      "|    clip_fraction        | 0.411       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.967       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.0178      |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 669        |\n",
      "|    ep_rew_mean          | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 186        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03327282 |\n",
      "|    clip_fraction        | 0.44       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.286      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.928      |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0322    |\n",
      "|    value_loss           | 0.0155     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 839        |\n",
      "|    ep_rew_mean          | 2.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 173        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04783895 |\n",
      "|    clip_fraction        | 0.458      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 0.108      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.957      |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0264    |\n",
      "|    value_loss           | 0.0151     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 507        |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 188        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06191551 |\n",
      "|    clip_fraction        | 0.452      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.25      |\n",
      "|    explained_variance   | 0.262      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.992      |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0241    |\n",
      "|    value_loss           | 0.0158     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 726         |\n",
      "|    ep_rew_mean          | 1.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 199         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041545942 |\n",
      "|    clip_fraction        | 0.458       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -0.314      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.948       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.00608     |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 538         |\n",
      "|    ep_rew_mean          | 0.333       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 178         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.078289896 |\n",
      "|    clip_fraction        | 0.455       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.962       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.0171      |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 601         |\n",
      "|    ep_rew_mean          | 0.667       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 198         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052622795 |\n",
      "|    clip_fraction        | 0.491       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.00835     |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 636        |\n",
      "|    ep_rew_mean          | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 184        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08183229 |\n",
      "|    clip_fraction        | 0.513      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.971      |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.022     |\n",
      "|    value_loss           | 0.00858    |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 572        |\n",
      "|    ep_rew_mean          | 0.667      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 185        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08085769 |\n",
      "|    clip_fraction        | 0.512      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.22      |\n",
      "|    explained_variance   | 0.193      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.975      |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0248    |\n",
      "|    value_loss           | 0.0121     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 863         |\n",
      "|    ep_rew_mean          | 2.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 195         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057221994 |\n",
      "|    clip_fraction        | 0.514       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.974       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.00844     |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 633        |\n",
      "|    ep_rew_mean          | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 197        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07774658 |\n",
      "|    clip_fraction        | 0.523      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.22      |\n",
      "|    explained_variance   | 0.212      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.948      |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0206    |\n",
      "|    value_loss           | 0.0198     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 611       |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 191       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 2048      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0720474 |\n",
      "|    clip_fraction        | 0.533     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.21     |\n",
      "|    explained_variance   | 0.273     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.963     |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -0.0292   |\n",
      "|    value_loss           | 0.0145    |\n",
      "---------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 614       |\n",
      "|    ep_rew_mean          | 1         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 196       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 2048      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1092006 |\n",
      "|    clip_fraction        | 0.539     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.2      |\n",
      "|    explained_variance   | 0.292     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.967     |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -0.0225   |\n",
      "|    value_loss           | 0.0124    |\n",
      "---------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 593         |\n",
      "|    ep_rew_mean          | 0.667       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.104204044 |\n",
      "|    clip_fraction        | 0.536       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.999       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 0.0105      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 624        |\n",
      "|    ep_rew_mean          | 0.667      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 196        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08789378 |\n",
      "|    clip_fraction        | 0.54       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.324      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.952      |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0215    |\n",
      "|    value_loss           | 0.00941    |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 527       |\n",
      "|    ep_rew_mean          | 0.333     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 198       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 2048      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1019579 |\n",
      "|    clip_fraction        | 0.557     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.22     |\n",
      "|    explained_variance   | 0.104     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1         |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -0.0181   |\n",
      "|    value_loss           | 0.00942   |\n",
      "---------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 686        |\n",
      "|    ep_rew_mean          | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 194        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09754267 |\n",
      "|    clip_fraction        | 0.568      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.21      |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.997      |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 0.00769    |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 634        |\n",
      "|    ep_rew_mean          | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 186        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11306384 |\n",
      "|    clip_fraction        | 0.568      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.21      |\n",
      "|    explained_variance   | 0.233      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.986      |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.0121     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 897        |\n",
      "|    ep_rew_mean          | 2.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 181        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11045578 |\n",
      "|    clip_fraction        | 0.574      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.21      |\n",
      "|    explained_variance   | 0.236      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.941      |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    value_loss           | 0.0122     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 706         |\n",
      "|    ep_rew_mean          | 1.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.122634664 |\n",
      "|    clip_fraction        | 0.59        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.94        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.0192      |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 796        |\n",
      "|    ep_rew_mean          | 2          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 180        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12742516 |\n",
      "|    clip_fraction        | 0.588      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.255      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.95       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    value_loss           | 0.0175     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 575        |\n",
      "|    ep_rew_mean          | 0.667      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 190        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13526301 |\n",
      "|    clip_fraction        | 0.587      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.271      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.949      |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0214    |\n",
      "|    value_loss           | 0.0153     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 948        |\n",
      "|    ep_rew_mean          | 3          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12609693 |\n",
      "|    clip_fraction        | 0.595      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.278      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.993      |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0171    |\n",
      "|    value_loss           | 0.00886    |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 573        |\n",
      "|    ep_rew_mean          | 0.667      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 165        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14706737 |\n",
      "|    clip_fraction        | 0.59       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.975      |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    value_loss           | 0.0191     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 647        |\n",
      "|    ep_rew_mean          | 1.33       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 196        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14734626 |\n",
      "|    clip_fraction        | 0.605      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.19      |\n",
      "|    explained_variance   | 0.478      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.982      |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.00127   |\n",
      "|    value_loss           | 0.00956    |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 534       |\n",
      "|    ep_rew_mean          | 0.333     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 195       |\n",
      "|    iterations           | 1         |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 2048      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1513835 |\n",
      "|    clip_fraction        | 0.59      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.16     |\n",
      "|    explained_variance   | 0.496     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.02      |\n",
      "|    n_updates            | 410       |\n",
      "|    policy_gradient_loss | -0.00803  |\n",
      "|    value_loss           | 0.0123    |\n",
      "---------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 684         |\n",
      "|    ep_rew_mean          | 1.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 191         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.113523655 |\n",
      "|    clip_fraction        | 0.616       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.000124   |\n",
      "|    value_loss           | 0.00629     |\n",
      "-----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 537        |\n",
      "|    ep_rew_mean          | 0.333      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 200        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14849538 |\n",
      "|    clip_fraction        | 0.585      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.368      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.977      |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    value_loss           | 0.0142     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 616        |\n",
      "|    ep_rew_mean          | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 182        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14937311 |\n",
      "|    clip_fraction        | 0.61       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.02       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    value_loss           | 0.0122     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 680        |\n",
      "|    ep_rew_mean          | 1.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 190        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14881998 |\n",
      "|    clip_fraction        | 0.596      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.471      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.955      |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.00298   |\n",
      "|    value_loss           | 0.0103     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 575        |\n",
      "|    ep_rew_mean          | 0.667      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 168        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15535878 |\n",
      "|    clip_fraction        | 0.606      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.417      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.998      |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    value_loss           | 0.0168     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 892        |\n",
      "|    ep_rew_mean          | 2.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 196        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13071263 |\n",
      "|    clip_fraction        | 0.602      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.985      |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | 0.00662    |\n",
      "|    value_loss           | 0.0104     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 616        |\n",
      "|    ep_rew_mean          | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 198        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15315294 |\n",
      "|    clip_fraction        | 0.616      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.02       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00218   |\n",
      "|    value_loss           | 0.0187     |\n",
      "----------------------------------------\n",
      "\n",
      " Saved RL agent\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 572        |\n",
      "|    ep_rew_mean          | 0.667      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 200        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13893849 |\n",
      "|    clip_fraction        | 0.606      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.491      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.975      |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | 0.00396    |\n",
      "|    value_loss           | 0.00979    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved RL agent\n",
      "Filling buffer with 1000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 215.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"C:/Users/jabad/Documents/Tuebingen/DataCompression/DataCompression\")\n",
    "sys.path.append(os.getcwd())\n",
    "from DataCompression.src.training_loop import Trainer\n",
    "from DataCompression.src.decoder_MSE import Decoder, CNN_AE\n",
    "from DataCompression.src.metric import evaluate\n",
    "\n",
    "config = {\n",
    "# \"rl_agent_train_steps\": 1,\n",
    "# \"decoder_train_steps\":10,\n",
    "\"buffer_size\": 1000,\n",
    "\"save_path\": \"C:/Users/jabad/Documents/Tuebingen/DataCompression/DataCompression/exp/Test_24_07\", \n",
    "\"alpha\": 1e-4\n",
    "}\n",
    "\n",
    "train_steps = 50000  # 10000?\n",
    "\n",
    "mytrainer = Trainer(**config)\n",
    "mytrainer.train_rl_agent(train_steps, save_every=1000)\n",
    "mytrainer.fill_buffer(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training decoder for 1000 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 1/1000, loss = 57.816411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [00:30<04:21,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 101/1000, loss = 57.818979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/1000 [01:00<03:53,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 201/1000, loss = 57.795596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/1000 [01:31<03:25,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 301/1000, loss = 57.743594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 400/1000 [02:01<02:50,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 401/1000, loss = 57.771206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 500/1000 [02:31<02:23,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 501/1000, loss = 57.776582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 600/1000 [03:01<02:05,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 601/1000, loss = 57.721919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 700/1000 [03:34<01:41,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 701/1000, loss = 57.795420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 800/1000 [04:07<00:57,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 801/1000, loss = 57.757056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 900/1000 [04:38<00:29,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 901/1000, loss = 57.698076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:10<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training decoder for 1000 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 1/1000, loss = 57.716792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [00:31<04:31,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 101/1000, loss = 57.712773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/1000 [01:02<04:13,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 201/1000, loss = 57.735913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/1000 [01:36<03:39,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 301/1000, loss = 57.646890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 400/1000 [02:05<02:59,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 401/1000, loss = 57.670151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 500/1000 [02:37<02:30,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 501/1000, loss = 57.703628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 600/1000 [03:08<02:05,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 601/1000, loss = 57.611260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 700/1000 [03:39<01:25,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 701/1000, loss = 57.665205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 800/1000 [04:09<00:59,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 801/1000, loss = 57.594785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 900/1000 [04:40<00:31,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 901/1000, loss = 57.601831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:11<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training decoder for 1000 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 1/1000, loss = 57.634404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [00:31<04:45,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 101/1000, loss = 57.603467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/1000 [01:03<04:07,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 201/1000, loss = 57.597900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/1000 [01:35<03:16,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 301/1000, loss = 57.592842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 400/1000 [02:04<02:48,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 401/1000, loss = 57.569956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 500/1000 [02:34<02:20,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 501/1000, loss = 57.535791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 600/1000 [03:04<02:05,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 601/1000, loss = 57.564131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 700/1000 [03:34<01:25,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 701/1000, loss = 57.511670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 800/1000 [04:03<00:56,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 801/1000, loss = 57.546641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 900/1000 [04:32<00:28,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 901/1000, loss = 57.527505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:02<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training decoder for 1000 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 1/1000, loss = 57.527095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [00:30<04:10,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 101/1000, loss = 57.473721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/1000 [00:59<03:44,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 201/1000, loss = 57.457964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/1000 [01:29<03:18,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 301/1000, loss = 57.434756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 400/1000 [01:58<02:47,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 401/1000, loss = 57.546880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 500/1000 [02:27<02:22,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 501/1000, loss = 57.452983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 600/1000 [02:57<01:53,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 601/1000, loss = 57.452754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 700/1000 [03:26<01:25,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 701/1000, loss = 57.297534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 800/1000 [03:56<01:04,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 801/1000, loss = 57.401733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 900/1000 [04:26<00:28,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch : 901/1000, loss = 57.413853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:55<00:00,  3.39it/s]\n"
     ]
    }
   ],
   "source": [
    "decoder_epochs = 4000  # total = 4000\n",
    "loss = mytrainer.train_Decoder(decoder_epochs, 100, save_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean entropy of each latent dim is: 0.00616544390985795\n",
      "The L2-loss in image space is: 5738.947265625\n",
      "The L2-loss in agent space is: 0.10811761021614075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00616544390985795, 5738.947265625, 0.10811761021614075)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = mytrainer._Decoder.model\n",
    "encoder = mytrainer._rl_agent.policy.features_extractor\n",
    "buffer = mytrainer._buffer\n",
    "flattened = True\n",
    "n_digits = 3\n",
    "\n",
    "evaluate(encoder, decoder, buffer, flattened, n_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test_images, test_latents = buffer.get_all()\n",
    "test_images_encoder = torch.reshape(test_images, (test_images.shape[0], 3, 210, 160))\n",
    "# forward pass of images\n",
    "latents = encoder(test_images_encoder)[0]\n",
    "latents = torch.round(latents * 10**n_digits) / (10**n_digits)\n",
    "reconstructed = decoder(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "reconstructed_reshaped = torch.reshape(reconstructed, (test_images.shape[0], 3, 210, 160)).detach().type(torch.int)\n",
    "test_images_int = test_images_encoder.type(torch.int)\n",
    "\n",
    "for i, (orig_image, recon_image) in enumerate(zip(test_images_int, reconstructed_reshaped)):\n",
    "    axs[0].set_title(\"Reconstructed image\")\n",
    "    axs[1].set_title(\"Original image\")\n",
    "    axs[0].imshow(recon_image.permute(1, 2, 0))\n",
    "    axs[1].imshow(orig_image.permute(1, 2, 0))\n",
    "    if i % 100 == 0:\n",
    "        fig.savefig('C:/Users/jabad/Documents/Tuebingen/DataCompression/DataCompression/exp/Test_24_07/orig_reconstructed' + str(i / 100) + '.png')\n",
    "    if i >= 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_with_rl(buffer, encoder, epochs=1000, batch_size=56):\n",
    "    # ----------------------\n",
    "    model = CNN_AE(in_dims=(1, 128, 1), out_dims=(3, 210, 160))\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    # -----------------------\n",
    "    print(f\"Training decoder for {epochs} epochs\")\n",
    "    time.sleep(1)  # to avoid printstream clashing with progressbar\n",
    "    # input as numpy arrays, change to tensors\n",
    "    # orig_images = torch.from_numpy(orig_images).float()\n",
    "    # lat_images = torch.from_numpy(lat_images).float()\n",
    "\n",
    "    # train\n",
    "    epoch_losses = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        orig_images, lat_images = buffer.sample(batch_size)  # TODO: replace by minibatch sampling\n",
    "        orig_images = torch.reshape(orig_images, (len(orig_images), 3, 210, 160))\n",
    "        total_loss = 0\n",
    "        # for (orig, latent) in zip(orig_images, lat_images):\n",
    "\n",
    "        # reset the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute reconstructions\n",
    "        lat_images = torch.unsqueeze(torch.unsqueeze(lat_images, 1), -1)\n",
    "        outputs = model(lat_images)\n",
    "\n",
    "        lat_reconstructed = encoder(outputs)\n",
    "\n",
    "        # compute reconstruction loss\n",
    "        lat_images = torch.squeeze(torch.squeeze(lat_images, 1), -1)\n",
    "        if epoch < 10000:\n",
    "            loss = criterion(orig_images, outputs)\n",
    "        else:\n",
    "            loss = criterion(lat_images, lat_reconstructed)\n",
    "\n",
    "\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # perform parameter update\n",
    "        optimizer.step()\n",
    "\n",
    "        # add this images's loss to epoch losses (loss per image normalized)\n",
    "        epoch_losses.append(loss.item() / batch_size)\n",
    "\n",
    "        # display the epoch training loss\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"\\n epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, epoch_losses[-1]))\n",
    "            time.sleep(1)  # to avoid printstream clashing with progressbar\n",
    "                \n",
    "    return epoch_losses, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_retrained_losses, rl_model = train_with_rl(mytrainer._buffer, mytrainer._rl_agent.policy.features_extractor, epochs=13000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = rl_model(torch.unsqueeze(torch.unsqueeze(latents, 1), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "reconstructed_reshaped = torch.reshape(reconstructed, (test_images.shape[0], 3, 210, 160)).detach().type(torch.int)\n",
    "\n",
    "for i, (orig_image, recon_image) in enumerate(zip(test_images_int, reconstructed_reshaped)):\n",
    "    axs[0].set_title(\"Reconstructed image\")\n",
    "    axs[1].set_title(\"Original image\")\n",
    "    axs[0].imshow(recon_image.permute(1, 2, 0))\n",
    "    axs[1].imshow(orig_image.permute(1, 2, 0))\n",
    "    if i % 100 == 0:\n",
    "        fig.savefig('orig_reconstructed_rl' + str(i / 100) + '.png')\n",
    "    if i >= 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b5be0c7d8816b0411dd8381c01b6ac4b538687487d40264816f7c3f94b5666c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
