{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics for JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataCompression.msc.Metric import Metric\n",
    "import numpy as np\n",
    "from DataCompression.src.decoder_MSE import CNN_AE\n",
    "from DataCompression.msc.vae_agarap import AE\n",
    "import torch\n",
    "from DataCompression.src.buffer import Decoder_Buffer\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a buffer for images of shape torch.Size([1000, 3, 210, 160]) and latents torch.Size([1000, 128])\n"
     ]
    }
   ],
   "source": [
    "# load the test dataset\n",
    "path = f\"C:/Users/jabad/Documents/Tuebingen/DataCompression/DataCompression/exp/test_dataset\"\n",
    "db = Decoder_Buffer([3, 210, 160], 128, 1000)\n",
    "db.load(path)\n",
    "images = db.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT run this if not using a new test set (will save 1000 images :) \n",
    "\n",
    "# convert to JPEG\n",
    "# to_PIL = transforms.ToPILImage()\n",
    "# for i, im in enumerate(images):\n",
    "#     image = im.clone()\n",
    "#     image = to_PIL(image)\n",
    "#     name = \"image\" + str(i) + \".jpg\"\n",
    "#     image.save(name, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate size (get size from size of folder)\n",
    "size = 4096000 * 8  # size on disk\n",
    "# size = 3246847 * 8  # convert to bits\n",
    "size = size / 1000  # get average size of one image\n",
    "dims = list(images[0].size())\n",
    "for dim in dims:\n",
    "    size /= dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the images\n",
    "image_path = f\"C:/Users/jabad/Documents/Tuebingen/DataCompression/DataCompression/exp/playground/jpgs_of_test/image\"\n",
    "reconstructed = torch.empty((1000, 3, 210, 160))\n",
    "for i in range(1000):\n",
    "    cur_im = image_path + str(i) + \".jpg\"\n",
    "    image = Image.open(cur_im)\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    image = to_tensor(image)\n",
    "    reconstructed[i] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the MSE loss\n",
    "criterion = torch.nn.MSELoss()\n",
    "loss = criterion(images, reconstructed).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "5748.169921875\n",
      "Size:\n",
      "0.3250793650793651\n"
     ]
    }
   ],
   "source": [
    "# print the results\n",
    "print(\"Accuracy:\")\n",
    "print(loss)\n",
    "print(\"Size:\")\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b5be0c7d8816b0411dd8381c01b6ac4b538687487d40264816f7c3f94b5666c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
